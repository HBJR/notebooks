{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f844acbd-e667-41dc-8df9-a2155f9fd98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim import corpora\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a62e48-f50c-4dc3-ac10-27c6474ecfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().cwd().parent / \"data\"\n",
    "model_dir = Path().cwd().parent / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aabaca9d-993e-48bd-ba61-4515ef473825",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(data_dir / \"cleaned_all_house.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da9eb194-fb32-41ce-9e6d-4e9eda9d5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class phraseIterator(object):\n",
    "\n",
    "    def __init__(self, inpath):\n",
    "        self.inpath = inpath\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.inpath, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if i == 0: continue\n",
    "                ls = line.split('\\t')\n",
    "                text = ls[1].replace('\\n','') \n",
    "                yield text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6cd7666c-a03c-40dc-b28e-4db94e0e7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class corpusIterator(object):\n",
    "\n",
    "    def __init__(self, inpath, bigram=None, trigram=None):\n",
    "        if bigram:\n",
    "            self.bigram = bigram\n",
    "        else:\n",
    "            self.bigram = None\n",
    "        if trigram:\n",
    "            self.trigram = trigram\n",
    "        else:\n",
    "            self.trigram = None\n",
    "        self.inpath = inpath\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.speeches = namedtuple('speeches', 'words tags')\n",
    "        with open(self.inpath, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if i == 0: continue\n",
    "                ls = line.split('\\t')\n",
    "                text = ls[1].replace('\\n','')\n",
    "                tokens = text.split()\n",
    "                if self.bigram and self.trigram:\n",
    "                    self.words = self.trigram[self.bigram[tokens]]\n",
    "                elif self.bigram and not self.trigram:\n",
    "                    self.words = self.bigram[tokens]\n",
    "                else:\n",
    "                    self.words = tokens\n",
    "                speaker = ls[2]\n",
    "                party = ls[3]\n",
    "                congress = ls[4].replace(\"\\n\",\"\")\n",
    "                tags = [f\"{party}\"]\n",
    "                self.tags = tags\n",
    "                yield TaggedDocument(self.words, self.tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "060410d7-9c2a-45f3-bf06-6416cdb48253",
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses = [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9627df68-54f1-4ba2-860f-45ebe470f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "year_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fdd902b-8b99-473a-9744-cb93c50d06e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [04:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42396\\2630670684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"temp.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbigram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     model0.train(corpusIterator(data_dir / \"temp.txt\", bigram=bigram, trigram=trigram), \n\u001b[0m\u001b[0;32m     13\u001b[0m              total_examples=model0.corpus_count, epochs=model0.epochs)\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start_doctags'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_doctags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         super(Doc2Vec, self).train(\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[0;32m   1074\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1432\u001b[0m             \u001b[0mthread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1434\u001b[1;33m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[0;32m   1435\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for congress in tqdm(congresses): \n",
    "    temp_df = full_df[full_df[\"congress\"] == congress]\n",
    "    temp_df.to_csv(data_dir / \"temp.txt\", sep=\"\\t\", index=False)\n",
    "    phrases = Phrases(phraseIterator(data_dir / \"temp.txt\"))\n",
    "    bigram = Phraser(phrases)\n",
    "    tphrases = Phrases(bigram[phraseIterator(data_dir / \"temp.txt\")])\n",
    "    trigram = Phraser(tphrases)\n",
    "    \n",
    "    \n",
    "    model0 = Doc2Vec(vector_size=200, window=20, min_count=50, workers=8, epochs=20)\n",
    "    model0.build_vocab(corpusIterator(data_dir / \"temp.txt\", bigram=bigram, trigram=trigram), min_count=50)\n",
    "    model0.train(corpusIterator(data_dir / \"temp.txt\", bigram=bigram, trigram=trigram), \n",
    "             total_examples=model0.corpus_count, epochs=model0.epochs)\n",
    "    \n",
    "    \n",
    "    speaker_tags = model0.dv.index_to_key\n",
    "    embeds = np.array([model0.dv[tag] for tag in speaker_tags])\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit_transform(embeds)\n",
    "    \n",
    "    pca_df = pd.DataFrame(pca.transform(embeds), columns=[\"pc1\", \"pc2\"])\n",
    "    \n",
    "    pca_df[\"tag\"] = speaker_tags\n",
    "\n",
    "    pca_df[[\"unique_id\",\"party\",\"congress\"]] = pca_df[\"tag\"].str.split('_', n=2, expand=True)\n",
    "    \n",
    "    year_means.append(pca_df.groupby(\"party\").mean([\"pc1\", \"pc2\"]))\n",
    "    \n",
    "    wordlist=[]\n",
    "    for word in model0.wv.key_to_index.keys():\n",
    "        wordlist.append((word, model0.wv.get_vecattr(word, \"count\")))\n",
    "    wordlist = sorted(wordlist, key=lambda tup: tup[1], reverse=True)\n",
    "    sorted_vocab = [w for w,c in wordlist if c>100 and c<1000000 and w.count('_')<3]\n",
    "\n",
    "    S = np.zeros((len(sorted_vocab), 2))\n",
    "\n",
    "    for idx, w in enumerate(sorted_vocab):\n",
    "        S[idx, :] = pca.transform(model0.wv[w].reshape(1,-1))\n",
    "        \n",
    "    temp = pd.DataFrame({'word': sorted_vocab, 'pc1': S.T[0], 'pc2':S.T[1]})\n",
    "    temp[\"congress\"] = congress\n",
    "    \n",
    "    df_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e8a43cf-a90b-43b8-8962-7e618f37f741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hbjro\\AppData\\Local\\Temp\\ipykernel_42396\\840545683.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  l_top = df.sort_values(\"pc1\")[\"word\"][:10]\n",
      "C:\\Users\\hbjro\\AppData\\Local\\Temp\\ipykernel_42396\\840545683.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  r_top = df.sort_values(\"pc1\", ascending=False)[\"word\"][:10]\n"
     ]
    }
   ],
   "source": [
    "right_top_words = {}\n",
    "left_top_words = {}\n",
    "\n",
    "for df in df_list: \n",
    "    l_top = df.sort_values(\"pc1\")[\"word\"][:10]\n",
    "    r_top = df.sort_values(\"pc1\", ascending=False)[\"word\"][:10]\n",
    "    congress = df[\"congress\"][0]\n",
    "    right_top_words[congress] = r_top\n",
    "    left_top_words[congress] = l_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfef22ab-8232-438a-8711-56d59455cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444            bureaucracy\n",
      "3255            bureaucrats\n",
      "3106      rules_regulations\n",
      "722               obamacare\n",
      "2819              overreach\n",
      "4041               red_tape\n",
      "1823          west_virginia\n",
      "3417        new_regulations\n",
      "1784                   farm\n",
      "4140    federal_regulations\n",
      "Name: word, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2482                         flint\n",
       "1567             voting_rights_act\n",
       "1602    congressional_black_caucus\n",
       "1677                    zika_virus\n",
       "877                  public_health\n",
       "2291                 voting_rights\n",
       "3257                    head_start\n",
       "1334             republican_budget\n",
       "2748                    fast_track\n",
       "1608                  civil_rights\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(left_top_words[114])\n",
    "right_top_words[114]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
