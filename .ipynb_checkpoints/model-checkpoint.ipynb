{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8205119f-f930-44ef-9630-ff9af9a5cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim import corpora\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c36516-a0bf-4452-8c69-a6db63aecc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().cwd().parent / \"data\"\n",
    "model_dir = Path().cwd().parent / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1c44d7-d0cb-498a-9e8c-81de97d14907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class phraseIterator(object):\n",
    "\n",
    "    def __init__(self, inpath):\n",
    "        self.inpath = inpath\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.inpath, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if i == 0: continue\n",
    "                ls = line.split('\\t')\n",
    "                text = ls[1].replace('\\n','') \n",
    "                yield text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93ca97d-f000-4f72-b5f5-64e8015e1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class corpusIterator(object):\n",
    "\n",
    "    def __init__(self, inpath, bigram=None, trigram=None):\n",
    "        if bigram:\n",
    "            self.bigram = bigram\n",
    "        else:\n",
    "            self.bigram = None\n",
    "        if trigram:\n",
    "            self.trigram = trigram\n",
    "        else:\n",
    "            self.trigram = None\n",
    "        self.inpath = inpath\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.speeches = namedtuple('speeches', 'words tags')\n",
    "        with open(self.inpath, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if i == 0: continue\n",
    "                ls = line.split('\\t')\n",
    "                text = ls[1].replace('\\n','')\n",
    "                tokens = text.split()\n",
    "                if self.bigram and self.trigram:\n",
    "                    self.words = self.trigram[self.bigram[tokens]]\n",
    "                elif self.bigram and not self.trigram:\n",
    "                    self.words = self.bigram[tokens]\n",
    "                else:\n",
    "                    self.words = tokens\n",
    "                speaker = ls[2]\n",
    "                party = ls[3]\n",
    "                congress = ls[4].replace(\"\\n\",\"\")\n",
    "                tags = [f\"{speaker}_{party}_{congress}\"]\n",
    "                self.tags = tags\n",
    "                yield TaggedDocument(self.words, self.tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad816511-2d7c-40e7-a8d7-fc04c0f61f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(phraseIterator(data_dir / \"cleaned_all_house.txt\"))\n",
    "bigram = Phraser(phrases)\n",
    "tphrases = Phrases(bigram[phraseIterator(data_dir / \"cleaned_all_house.txt\")])\n",
    "trigram = Phraser(tphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfeb8e4-fb3a-4cf8-bb47-da9cc87df04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Doc2Vec(vector_size=200, window=20, min_count=50, workers=8, epochs=20)\n",
    "model0.build_vocab(corpusIterator(data_dir / \"cleaned_all_house.txt\", bigram=bigram, trigram=trigram), min_count=50)\n",
    "model0.train(corpusIterator(data_dir / \"cleaned_all_house.txt\", bigram=bigram, trigram=trigram), \n",
    "             total_examples=model0.corpus_count, epochs=model0.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "262f9ed1-df4c-41a7-af3d-5974ada00092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.save(\"../models/main_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2fc75a-5ff4-4cb0-bf36-5db44220c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.save(\"../models/all_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
