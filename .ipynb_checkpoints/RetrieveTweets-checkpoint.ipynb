{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0264bb2b-cd5c-4eb0-ab28-b1b0daa644ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5427e0bb-7039-4a44-a6ef-f5e7eb2a7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = f\"..{os.sep}.env\"\n",
    "\n",
    "dotenv.load_dotenv(ENV_PATH) # This will refresh the environment variables\n",
    "\n",
    "BEARER = os.environ[\"TWITTER_BEARER_TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7789f57c-420f-4cbc-90d4-535329be37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {BEARER}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5d0bce-e4e3-425a-95c5-51f13bb0a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(year = 2022, month = 1, day = 1).astimezone().isoformat()\n",
    "end_time = datetime(year = 2022, month = 12, day = 31).astimezone().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ae80f68-ec0f-4e55-b329-e40dab177134",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_count = \"https://api.twitter.com/2/tweets/counts/all\"\n",
    "\n",
    "params={\n",
    "        \"query\":f\"from:BBCNews\",\n",
    "        \"start_time\":start_time,\n",
    "        \"end_time\":end_time,\n",
    "        \"granularity\":\"day\"\n",
    "        }\n",
    "\n",
    "response = requests.get(tweets_count, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f8ce978c-b9c3-4603-a5b0-fb9ff3020415",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in response.json()[\"data\"]:\n",
    "    count+= i['tweet_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "378d9930-cd47-4dac-be97-14764bdb6d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2491"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29253d5-70bc-4cae-9509-ade4f1db43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "\n",
    "def get_tweets(screen_name, start_time=start_time, end_time=end_time):\n",
    "    json_list = []\n",
    "    search_tweets = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    page_token = None\n",
    "    while True: \n",
    "        \n",
    "        params={\n",
    "        \"query\":f\"from:{screen_name}\",\n",
    "        \"tweet.fields\":\"entities,public_metrics,created_at\",\n",
    "        \"pagination_token\": page_token,\n",
    "        \"max_results\":500, \n",
    "        \"expansions\":\"author_id\", \n",
    "        \"start_time\":start_time,\n",
    "        \"end_time\":end_time\n",
    "        }\n",
    "        \n",
    "        response = requests.get(search_tweets, params=params, headers=headers)\n",
    "        \n",
    "        if \"title\" in response.json().keys():\n",
    "            if response.json()[\"status\"] == 429: \n",
    "                print(\"Rate limit reached. waiting 15 minutes\")\n",
    "                time.sleep(900)\n",
    "                continue\n",
    "            if response.json()[\"status\"] == 503: \n",
    "                print(\"Service overloaded. waiting 15 minutes\")\n",
    "                time.sleep(900)\n",
    "                continue\n",
    "            else: \n",
    "                print(\"Encountered unknown error pickling current results and stopping program\")\n",
    "                with open(f'{screen_name}_datafile.txt', 'wb') as fh:\n",
    "                       pickle.dump(json_list, fh)\n",
    "                        \n",
    "        if response.json()[\"meta\"][\"result_count\"] == 0: \n",
    "            break\n",
    "        \n",
    "        json_list.append(response.json())\n",
    "        time.sleep(1)\n",
    "                     \n",
    "        try: \n",
    "            page_token = response.json()['meta']['next_token']\n",
    "        except: \n",
    "            break\n",
    "    return json_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "376f1207-6342-460d-b9c8-b9f305c10d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "media_list = [\"bbcnews\", \"itvnews\", \"Channel4News\", \"guardian\", \"MailOnline\",\n",
    "              \"thetimes\", \"Telegraph\", \"TheSun\", \"SkyNews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "428c3992-fbf6-4645-919a-b55ccf2d30b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service overloaded. waiting 15 minutes\n",
      "Service overloaded. waiting 15 minutes\n",
      "Service overloaded. waiting 15 minutes\n"
     ]
    }
   ],
   "source": [
    "for i in media_list: \n",
    "    \n",
    "    results = get_tweets(i)\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for j in results:\n",
    "        df_list.append(pd.json_normalize(j[\"data\"]))\n",
    "    \n",
    "    total_df = pd.concat(df_list, ignore_index = True)\n",
    "\n",
    "    total_df.to_csv(f'../data/media_tweets/{i}.csv')\n",
    "    total_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32447cd0-24b2-4dcb-83a2-68f492c5a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_df = pd.read_csv(\"../data/2019_MPs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060a8946-3b8b-4ca7-99d2-bef509979062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. waiting 15 minutes\n",
      "Rate limit reached. waiting 15 minutes\n",
      "Service overloaded. waiting 15 minutes\n",
      "Rate limit reached. waiting 15 minutes\n",
      "Service overloaded. waiting 15 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, len(mp_df)):\n",
    "    \n",
    "    screen_name = mp_df.iloc[i]['twitter_username']\n",
    "    if pd.isna(screen_name): continue\n",
    "    start_time = mp_df.iloc[i]['start_time']\n",
    "    end_time = mp_df.iloc[i]['end_time']\n",
    "    results = get_tweets(screen_name, start_time, end_time)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for j in results:\n",
    "        df_list.append(pd.json_normalize(j[\"data\"]))\n",
    "    if len(df_list) > 0: \n",
    "        total_df = pd.concat(df_list, ignore_index = True)\n",
    "        total_df.to_csv(f'../data/mp_tweets/{screen_name}.csv')\n",
    "    else: continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde73fc-84b1-4b22-9205-6f026a8348c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
