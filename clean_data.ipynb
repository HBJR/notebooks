{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8c83a1-236b-4acd-acf9-1dbd9b2e483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98011860-0a2d-40eb-a4e1-f2f3a016b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().cwd().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da4c536-de18-492c-9629-fa730966a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_map = {\"you'd\": 'you would', \"he'd\": 'he would', \"she's\": 'she is', \"where'd\": 'where did', \"might've\": 'might have', \\\n",
    "                \"he'll\": 'he will', \"they'll\": 'they will',  \"mightn't\": 'might not', \"you'd've\": 'you would have', \"shan't\": 'shall not', \\\n",
    "                \"it'll\": 'it will', \"mayn't\": 'may not', \"couldn't\": 'could not', \"they'd\": 'they would', \"so've\": 'so have', \\\n",
    "                \"needn't've\": 'need not have', \"they'll've\": 'they will have', \"it's\": 'it is', \"haven't\": 'have not', \"didn't\": 'did not', \\\n",
    "                \"y'all'd\": 'you all would', \"needn't\": 'need not', \"who'll\": 'who will', \"wouldn't've\": 'would not have', \"when's\": 'when is', \\\n",
    "                \"will've\": 'will have', \"it'd've\": 'it would have', \"what'll\": 'what will', \"that'd've\": 'that would have', \\\n",
    "                \"y'all're\": 'you all are', \"let's\": 'let us', \"where've\": 'where have', \"o'clock\": 'oclock', \"when've\": 'when have', \\\n",
    "                \"what're\": 'what are', \"should've\": 'should have', \"you've\": 'you have', \"they're\": 'they are', \"aren't\": 'are not', \\\n",
    "                \"they've\": 'they have', \"it'd\": 'it would', \"i'll've\": 'i will have', \"they'd've\": 'they would have', \"you'll've\": 'you will have', \\\n",
    "                \"wouldn't\": 'would not', \"we'd\": 'we would', \"hadn't've\": 'had not have', \"weren't\": 'were not', \"i'd\": 'i would', \\\n",
    "                \"must've\": 'must have', \"what's\": 'what is', \"mustn't've\": 'must not have', \"what'll've\": 'what will have', \"ain't\": 'aint', \\\n",
    "                \"doesn't\": 'does not', \"we'll\": 'we will', \"i'd've\": 'i would have', \"we've\": 'we have', \"oughtn't\": 'ought not', \\\n",
    "                \"you're\": 'you are', \"who'll've\": 'who will have', \"shouldn't\": 'should not', \"can't've\": 'cannot have', \"i've\": 'i have', \\\n",
    "                \"couldn't've\": 'could not have', \"why've\": 'why have', \"what've\": 'what have', \"can't\": 'cannot', \"don't\": 'do not', \\\n",
    "                \"that'd\": 'that would', \"who's\": 'who is', \"would've\": 'would have', \"there'd\": 'there would', \"shouldn't've\": 'should not have', \\\n",
    "                \"y'all\": 'you all', \"mustn't\": 'must not', \"she'll\": 'she will', \"hadn't\": 'had not', \"won't've\": 'will not have', \\\n",
    "                \"why's\": 'why is', \"'cause\": 'because', \"wasn't\": 'was not', \"shan't've\": 'shall not have', \"ma'am\": 'madam', \"hasn't\": 'has not', \\\n",
    "                \"to've\": 'to have', \"how'll\": 'how will', \"oughtn't've\": 'ought not have', \"he'll've\": 'he will have', \"we'd've\": 'we would have', \\\n",
    "                \"won't\": 'will not', \"could've\": 'could have', \"isn't\": 'is not', \"she'll've\": 'she will have', \"we'll've\": 'we will have', \\\n",
    "                \"you'll\": 'you will', \"who've\": 'who have', \"there's\": 'there is', \"y'all've\": 'you all have', \"we're\": 'we are', \"i'll\": 'i will', \\\n",
    "                \"i'm\": 'i am', \"how's\": 'how is', \"she'd've\": 'she would have', \"sha'n't\": 'shall not', \"there'd've\": 'there would have', \\\n",
    "                \"he's\": 'he is', \"it'll've\": 'it will have', \"that's\": 'that is', \"y'all'd've\": 'you all would have', \"he'd've\": 'he would have', \\\n",
    "                \"how'd\": 'how did', \"where's\": 'where is', \"so's\": 'so as', \"she'd\": 'she would', \"mightn't've\": 'might not have'}\n",
    "\n",
    "procedural_words = ['member','members','president',\n",
    "    'hon','parliament','house','ask','asked','asks','question','questioned','questions','bills','bill',\n",
    "    'party','parties','mp','mps','sir','madam','mr','gentleman','gentlemen','lady','ladies',\n",
    "    'speaker','chair','motion','motions','vote','votes','order','yes','deputy','secretary',\n",
    "    'chairman','chairwoman',\n",
    "    'america','usa','american','americans',\n",
    "    'pursuant','supply','supplementary','please','friend','s',\n",
    "    'clause','amendment','i','ii','iii','section','sections', 'colleague', 'colleagues']\n",
    "\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c6254c-47ed-438b-8563-8e5d33b32aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    text = reduce(lambda a, kv: a.replace(*kv), contractions_map.items(), text.lower())\n",
    "    text = text.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "    text = text.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation)))\n",
    "    \n",
    "    tokens = word_tokenize(text) \n",
    "    \n",
    "    tokens = [w for w in tokens if w not in stop_words and w not in procedural_words and len(w)>2 and w!=' ' and not w.isdigit()]\n",
    "    \n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea7dcf0-4c21-4ef5-9846-8f6adeb818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker(speakerid): \n",
    "    speakerid=str(speakerid)\n",
    "    return \"\".join([*speakerid][3:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bad8a7c-61f7-4238-9f1d-56715ddbe864",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_102_to_108 = pd.read_csv(data_dir / \"house_102_to_108.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e570424e-a62a-452a-8488-8c3f0a57e9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.87319811738882"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_102_to_108[\"speech\"].map(lambda x: len(x.split())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd524fa7-33d1-4e34-931d-74a41b6507ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congress</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>441.0</td>\n",
       "      <td>181.496599</td>\n",
       "      <td>219.021057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>121.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>440.0</td>\n",
       "      <td>172.536364</td>\n",
       "      <td>217.981554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>2284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>439.0</td>\n",
       "      <td>234.981777</td>\n",
       "      <td>239.843127</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>152.0</td>\n",
       "      <td>301.5</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>443.0</td>\n",
       "      <td>166.067720</td>\n",
       "      <td>168.328675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>435.0</td>\n",
       "      <td>168.048276</td>\n",
       "      <td>159.060186</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>438.0</td>\n",
       "      <td>123.488584</td>\n",
       "      <td>128.189089</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.25</td>\n",
       "      <td>85.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>437.0</td>\n",
       "      <td>140.322654</td>\n",
       "      <td>146.166327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>92.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std  min    25%    50%    75%     max\n",
       "congress                                                                 \n",
       "102       441.0  181.496599  219.021057  2.0  56.00  121.0  219.0  2775.0\n",
       "103       440.0  172.536364  217.981554  1.0  50.00  109.0  207.5  2284.0\n",
       "104       439.0  234.981777  239.843127  7.0  78.00  152.0  301.5  1715.0\n",
       "105       443.0  166.067720  168.328675  1.0  55.00  115.0  219.5  1404.0\n",
       "106       435.0  168.048276  159.060186  2.0  62.00  123.0  214.0  1299.0\n",
       "107       438.0  123.488584  128.189089  3.0  46.25   85.0  154.0   906.0\n",
       "108       437.0  140.322654  146.166327  1.0  49.00   92.0  189.0  1027.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_102_to_108.groupby([\"congress\", \"speakerid\"]).size().groupby(\"congress\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528311ea-0567-4ff8-8bd3-ecf80224d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_102_to_108[\"cleaned_speech\"] = house_102_to_108[\"speech\"].map(clean_text)\n",
    "house_102_to_108[\"cleaned_speaker\"] = house_102_to_108[\"speakerid\"].map(extract_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26da221e-4b3a-4627-bbc5-37b3afd7a9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "house_102_to_108 = house_102_to_108[[\"speech_id\", \"cleaned_speech\", \"cleaned_speaker\", \"party\", \"congress\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9ae4f3-56ea-4b7f-a200-8b6330608d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_102_to_108.to_csv(data_dir / \"cleaned_house_102_to_108.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf37a92c-7c54-451f-8185-42ecce68556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_ids = pd.read_csv(data_dir / \"fox_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254ed37e-a2f6-43ac-8fbb-bdf83f03a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_ids[\"unique_id\"] = fox_ids[\"unique_id\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2851dd23-a62a-4dad-b816-37747b7750b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_house_102_to_108 = house_102_to_108.merge(fox_ids, how=\"inner\", left_on=\"cleaned_speaker\", right_on=\"unique_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33644300-3d5b-46d2-bdff-36dd042c38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_house_102_to_108.to_csv(data_dir / \"fox_house_102_to_108.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd9335-79a1-42d8-884b-840a0c31e09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
